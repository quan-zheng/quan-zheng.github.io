[{"authors":null,"categories":null,"content":"This feature can be used for publishing content such as:\n Project or software documentation Online courses Tutorials  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.\nTo disable this feature, either delete the parent folder, or set draft = true in the front matter of all its pages.\nAfter renaming or deleting the parent folder, you may wish to update any [[menu.main]] menu links to it in the config.toml.\n","date":1536465600,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536465600,"objectID":"c3224f3a64174f08aaf31e1f1d16ffd3","permalink":"https://quan-zheng.github.io/tutorial/","publishdate":"2018-09-09T00:00:00-04:00","relpermalink":"/tutorial/","section":"tutorial","summary":"This feature can be used for publishing content such as:\n Project or software documentation Online courses Tutorials  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.\nTo disable this feature, either delete the parent folder, or set draft = true in the front matter of all its pages.\nAfter renaming or deleting the parent folder, you may wish to update any [[menu.","tags":null,"title":"Overview","type":"docs"},{"authors":["Quan Zheng","Matthias Zwicker"],"categories":null,"content":" Preprint [PDF (19.4 MB)]\n Supplementary materials [PDF (6.3 MB)]\n Bibtex [bibtex]\n  ","date":1546318800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546318800,"objectID":"f4d60f2ac66082e662204b74d4501a89","permalink":"https://quan-zheng.github.io/publication/impsamplepss19/","publishdate":"2019-01-01T00:00:00-05:00","relpermalink":"/publication/impsamplepss19/","section":"publication","summary":"Importance sampling is one of the most widely used variance reduction strategies in Monte Carlo rendering. In this paper, we propose a novel importance sampling technique that uses a neural network to learn how to sample from a desired density represented by a set of samples. Our approach considers an existing Monte Carlo rendering algorithm as a black box. During a scene-dependent training phase, we learn to generate samples with a desired density in the primary sample space of the rendering algorithm using maximum likelihood estimation. We leverage a recent neural network architecture that was designed to represent real-valued non-volume preserving (Real NVP) transformations in high dimensional spaces. We use Real NVP to non-linearly warp primary sample space and obtain desired densities. In addition, Real NVP efficiently computes the determinant of the Jacobian of the warp, which is required to implement the change of integration variables implied by the warp. A main advantage of our approach is that it is agnostic of underlying light transport effects, and can be combined with an existing rendering technique by treating it as a black box. We show that our approach leads to effective variance reduction in several practical scenarios.","tags":[],"title":"Learning to importance sample in primary sample space","type":"publication"},{"authors":null,"categories":null,"content":" In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;\n","date":1536465600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536465600,"objectID":"6a451186c775f5f0adb3a0416d0cb711","permalink":"https://quan-zheng.github.io/tutorial/example/","publishdate":"2018-09-09T00:00:00-04:00","relpermalink":"/tutorial/example/","section":"tutorial","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;","tags":null,"title":"Example Page","type":"docs"},{"authors":["Yu Liu","Changwen Zheng","Quan Zheng","Hongliang Yuan"],"categories":null,"content":"","date":1514852481,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514852481,"objectID":"8344c7a1989f09362d579ed05a10f8d1","permalink":"https://quan-zheng.github.io/publication/removemcnoise18/","publishdate":"2018-01-01T19:21:21-05:00","relpermalink":"/publication/removemcnoise18/","section":"publication","summary":"","tags":[],"title":"Removing Monte Carlo Noise Using a Sobel Operator and a Guided Image Filter","type":"publication"},{"authors":["Quan Zheng","Changwen Zheng"],"categories":null,"content":"More detail can easily be written here using Markdown and $\\rm \\LaTeX$ math code.\n","date":1491019200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1491019200,"objectID":"c55ff29139cdb0a05231277cff32205a","permalink":"https://quan-zheng.github.io/publication/neurolens16/","publishdate":"2017-04-01T00:00:00-04:00","relpermalink":"/publication/neurolens16/","section":"publication","summary":"Rendering with full lens model can offer images with photorealistic lens effects, but it leads to high computational costs. This paper proposes a novel camera lens model, NeuroLens, to emulate the imaging of real camera lenses through a data‐driven approach. The mapping of image formation in a camera lens is formulated as imaging regression functions (IRFs), which map input rays to output rays. IRFs are approximated with neural networks, which compactly represent the imaging properties and support parallel evaluation on a graphics processing unit (GPU). To effectively represent spatially varying imaging properties of a camera lens, the input space spanned by incident rays is subdivided into multiple subspaces and each subspace is fitted with a separate IRF. To further raise the evaluation accuracy, a set of neural networks is trained for each IRF and the output is calculated as the average output of the set. The effectiveness of the NeuroLens is demonstrated by fitting a wide range of real camera lenses. Experimental results show that it provides higher imaging accuracy in comparison to state‐of‐the‐art camera lens models, while maintaining the high efficiency for processing camera rays.","tags":[],"title":"NeuroLens: data-driven camera lens simulation using neural networks","type":"publication"},{"authors":["Quan Zheng","Changwen Zheng"],"categories":null,"content":"More detail can easily be written here using Markdown and $\\rm \\LaTeX$ math code.\n","date":1488344400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1488344400,"objectID":"270f5c40936032920bb72daafa8d8608","permalink":"https://quan-zheng.github.io/publication/polylens17/","publishdate":"2017-03-01T00:00:00-05:00","relpermalink":"/publication/polylens17/","section":"publication","summary":"Lens effects are crucial visual elements in the synthetic imagery, but rendering lens effects with complex full lens models is time-consuming. This paper proposes a polynomial regression-based approach for constructing a sparse and accurate polynomial lens model. Terms of a polynomial are built adaptively in a bottom-up approach. Depending on the distribution of aberrations, this approach partitions the light field and builds separate polynomial models for local light fields. A line pupil-based sampling method is presented to accelerate the generation of camera rays. In addition, a new Monte Carlo estimator is derived to support general Monte Carlo rendering. Experiments show that this approach significantly reduces the time cost of constructing a polynomial lens model in comparison to state-of-the-art methods, while achieving high imaging accuracy.","tags":[],"title":"Adaptive sparse polynomial regression for camera lens simulation","type":"publication"},{"authors":["Hongliang Yuan","Changwen Zheng","Quan Zheng","Yu Liu"],"categories":null,"content":"","date":1485994881,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1485994881,"objectID":"60abcb5c1753b9838255f5750ee6ff8d","permalink":"https://quan-zheng.github.io/publication/17grapp_adaptiveorderselection/","publishdate":"2017-02-01T19:21:21-05:00","relpermalink":"/publication/17grapp_adaptiveorderselection/","section":"publication","summary":"","tags":[],"title":"Adaptive rendering with adaptive order selection","type":"publication"},{"authors":[],"categories":null,"content":"Click on the Slides button above to view the built-in slides feature.\n\rSlides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using url_slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1483246800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483246800,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"https://quan-zheng.github.io/talk/example/","publishdate":"2017-01-01T00:00:00-05:00","relpermalink":"/talk/example/","section":"talk","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam.","tags":[],"title":"Example Talk","type":"talk"},{"authors":["Quan Zheng","Changwen Zheng"],"categories":null,"content":"","date":1462148481,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1462148481,"objectID":"c46e81677aa0d417cf6e80767b05d1be","permalink":"https://quan-zheng.github.io/publication/16icnc_adaptivelightpathssampling/","publishdate":"2016-05-01T19:21:21-05:00","relpermalink":"/publication/16icnc_adaptivelightpathssampling/","section":"publication","summary":"","tags":[],"title":"Adaptive light paths sampling through full lens model","type":"publication"},{"authors":null,"categories":null,"content":"","date":1461729600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461729600,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"https://quan-zheng.github.io/project/external-project/","publishdate":"2016-04-27T00:00:00-04:00","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461729600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461729600,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"https://quan-zheng.github.io/project/internal-project/","publishdate":"2016-04-27T00:00:00-04:00","relpermalink":"/project/internal-project/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Internal Project","type":"project"},{"authors":[],"categories":null,"content":" Academic makes it easy to create a beautiful website for free using Markdown. Customize anything on your site with widgets, themes, and language packs.\nFollow our easy step by step guide to learn how to build your own free website with Academic. Check out the personal demo or the business demo of what you\u0026rsquo;ll get in less than 10 minutes.\n View the documentation Ask a question Request a feature or report a bug Updating? View the Update Guide and Release Notes Support development of Academic:  Donate a coffee Become a backer on Patreon Decorate your laptop or journal with an Academic sticker Wear the T-shirt   \nKey features:\n Easily manage various content including homepage, blog posts, publications, talks, and projects Extensible via color themes and widgets/plugins Write in Markdown for easy formatting and code highlighting, with LaTeX for mathematical expressions Social/academic network linking, Google Analytics, and Disqus comments Responsive and mobile friendly Simple and refreshing one page design Multilingual and easy to customize  Color Themes Academic is available in different color themes and font themes.\n\r\r\r\r\r\r\r\r Ecosystem  Academic Admin: An admin tool to import publications from BibTeX or import assets for an offline site Academic Scripts: Scripts to help migrate content to new versions of Academic  Install You can choose from one of the following four methods to install:\n one-click install using your web browser (recommended) install on your computer using Git with the Command Prompt/Terminal app install on your computer by downloading the ZIP files install on your computer with RStudio  Quick install using your web browser  Install Academic with Netlify  Netlify will provide you with a customizable URL to access your new site  On GitHub, go to your newly created academic-kickstart repository and edit config.toml to personalize your site. Shortly after saving the file, your site will automatically update Read the Quick Start Guide to learn how to add Markdown content. For inspiration, refer to the Markdown content which powers the Demo  Install with Git Prerequisites:\n Download and install Git Download and install Hugo   Fork the Academic Kickstart repository and clone your fork with Git:\ngit clone https://github.com/sourcethemes/academic-kickstart.git My_Website  Note that if you forked Academic Kickstart, the above command should be edited to clone your fork, i.e. replace sourcethemes with your GitHub username.\n Initialize the theme:\ncd My_Website git submodule update --init --recursive   Install with ZIP  Download and extract Academic Kickstart Download and extract the Academic theme to the themes/academic/ folder from the above step  Install with RStudio View the guide to installing Academic with RStudio\nQuick start  If you installed on your computer, view your new website by running the following command:\nhugo server  Now visit localhost:1313 and your new Academic powered website will appear. Otherwise, if using Netlify, they will provide you with your URL.\n Read the Quick Start Guide to learn how to add Markdown content, customize your site, and deploy it. For inspiration, refer to the Markdown content which powers the Demo\n Build your site by running the hugo command. Then host it for free using Github Pages or Netlify (refer to the first installation method). Alternatively, copy the generated public/ directory (by FTP, Rsync, etc.) to your production web server (such as a university\u0026rsquo;s hosting service).\n  Updating Feel free to star the project on Github to help keep track of updates and check out the release notes prior to updating your site.\nBefore updating the framework, it is recommended to make a backup of your entire website directory (or at least your themes/academic directory) and record your current version number.\nBy default, Academic is installed as a Git submodule which can be updated by running the following command:\ngit submodule update --remote --merge  Check out the update guide for full instructions and alternative methods.\nFeedback \u0026amp; Contributing Please use the issue tracker to let me know about any bugs or feature requests, or alternatively make a pull request.\nFor support, head over to the Hugo discussion forum.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1461124800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1515819600,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"https://quan-zheng.github.io/post/getting-started/","publishdate":"2016-04-20T00:00:00-04:00","relpermalink":"/post/getting-started/","section":"post","summary":"Create a beautifully simple website or blog in under 10 minutes.","tags":["Academic"],"title":"Academic: the website designer for Hugo","type":"post"},{"authors":["Quan Zheng","Changwen Zheng"],"categories":null,"content":"More detail can easily be written here using Markdown and $\\rm \\LaTeX$ math code.\n","date":1433131200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1433131200,"objectID":"d12c16ab329bd5eafd6b5ab799928552","permalink":"https://quan-zheng.github.io/publication/viapt15/","publishdate":"2015-06-01T00:00:00-04:00","relpermalink":"/publication/viapt15/","section":"publication","summary":"We present a mobile visual clothing search system whereby a smart phone user can either choose a social networking photo or take a new photo of a person wearing clothing of interest and search for similar clothing in a retail database. From the query image, the person is detected, clothing is segmented, and clothing features are extracted and quantized. The information is sent from the phone client to a server, where the feature vector of the query image is used to retrieve similar clothing products from online databases. The phone's GPS location is used to re-rank results by retail store location. State of the art work focuses primarily on the recognition of a diverse range of clothing offline and pays little attention to practical applications. Evaluated on a challenging dataset, the system is relatively fast and achieves promising results.","tags":[],"title":"Visual importance-based adaptive photon tracing","type":"publication"},{"authors":["Ye Cheng","Quan Zheng","Junkai Peng","Pin Lv","Changwen Zheng"],"categories":null,"content":"","date":1430526081,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1430526081,"objectID":"5c0d56fa187dad641f8c662cb83aac1e","permalink":"https://quan-zheng.github.io/publication/18spie_opticalsimulation/","publishdate":"2015-05-01T19:21:21-05:00","relpermalink":"/publication/18spie_opticalsimulation/","section":"publication","summary":"","tags":[],"title":"Optical simulation based on physically based renderer","type":"publication"},{"authors":["Quan Zheng","Changwen Zheng"],"categories":null,"content":"","date":1427934081,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1427934081,"objectID":"9dc3c2abb59df5268e6a2a1a7375766f","permalink":"https://quan-zheng.github.io/publication/15icig_photonshooting/","publishdate":"2015-04-01T19:21:21-05:00","relpermalink":"/publication/15icig_photonshooting/","section":"publication","summary":"","tags":[],"title":"Photon shooting with programmable scalar contribution function","type":"publication"},{"authors":["Quan Zheng","Changwen Zheng"],"categories":null,"content":"","date":1417479681,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1417479681,"objectID":"9b696a78cac0039a4691a9026f26d3b7","permalink":"https://quan-zheng.github.io/publication/14jcadcg_visualimportance/","publishdate":"2014-12-01T19:21:21-05:00","relpermalink":"/publication/14jcadcg_visualimportance/","section":"publication","summary":"","tags":[],"title":"Adaptive Photon tracing with Visual Importance Guidance","type":"publication"},{"authors":["Quan Zheng","Changwen Zheng","Fukun Wu","Huafei Yin"],"categories":null,"content":"","date":1396398081,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1396398081,"objectID":"36a7ac97b3f76dcdb48f2e751f3a4ab4","permalink":"https://quan-zheng.github.io/publication/14jcadcg_lensghost/","publishdate":"2014-04-01T19:21:21-05:00","relpermalink":"/publication/14jcadcg_lensghost/","section":"publication","summary":"","tags":[],"title":"Realistic Rendering of Lens Ghost Effects","type":"publication"},{"authors":null,"categories":null,"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne\r Two\r Three\r\nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c2915ec5da95791851caafdcba9664af","permalink":"https://quan-zheng.github.io/slides/example-slides/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/slides/example-slides/","section":"slides","summary":"Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$","tags":null,"title":"Slides","type":"slides"}]